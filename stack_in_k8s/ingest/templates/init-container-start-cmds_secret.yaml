
{{- define "datawave.datawaveInitContainer" -}}
#!/bin/bash -e

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
cd $DIR
echo "Symlinking Artifactory Repo"
ln -s /secrets/artifactory.repo /etc/yum.repos.d/artifactory.repo

export ROOT_DATAWAVE_HDFS_DIR=hdfs://hdfs-nn:9000/datawave/
export DW_ACCUMULO_VFS_DATAWAVE_DIR=${ROOT_DATAWAVE_HDFS_DIR}accumulo-vfs-classpath
export HADOOP_HOME=/usr/local/hadoop
export DW_DATAWAVE_INGEST_HOME=/opt/datawave-ingest/current/
echo "Creating temp dir in hdfs"
${HADOOP_HOME}/bin/hdfs dfs -mkdir -p hdfs://hdfs-nn:9000/tmp/hadoop-yarn
${HADOOP_HOME}/bin/hdfs dfs -chmod -777 -r hdfs://hdfs-nn:9000/tmp/

echo "Creating myjson dir"
${HADOOP_HOME}/bin/hdfs dfs -mkdir -p hdfs://hdfs-nn:9000/data/myjson
echo "Creating classpath dir"
${HADOOP_HOME}/bin/hdfs dfs -mkdir -p "${DW_ACCUMULO_VFS_DATAWAVE_DIR}"

echo "Updating permissions on /datawave in hdfs"
${HADOOP_HOME}/bin/hdfs dfs -chown datawave "${ROOT_DATAWAVE_HDFS_DIR}"

echo "Updating permissions on /data in hdfs"
${HADOOP_HOME}/bin/hdfs dfs -chown -R datawave hdfs://hdfs-nn:9000/data
echo "Copying DataWave jars into HDFS dir: ${DW_ACCUMULO_VFS_DATAWAVE_DIR}"
if [ -d ${DW_DATAWAVE_INGEST_HOME}/accumulo-warehouse/lib ]; then
  ${HADOOP_HOME}/bin/hdfs dfs -put -f ${DW_DATAWAVE_INGEST_HOME}/accumulo-warehouse/lib/*.jar ${DW_ACCUMULO_VFS_DATAWAVE_DIR}
fi
if [ -d ${DW_DATAWAVE_INGEST_HOME}/accumulo-warehouse/lib/ext ]; then
  ${HADOOP_HOME}/bin/hdfs dfs -put -f ${DW_DATAWAVE_INGEST_HOME}/accumulo-warehouse/lib/ext/*.jar ${DW_ACCUMULO_VFS_DATAWAVE_DIR}
fi
{{- end -}}

apiVersion: v1
kind: Secret
metadata:
  name: {{ include "datawave.fullname" . }}-initconatiner-cmds
  labels:
    {{- include "datawave.labels" . | nindent 4 }}
type: Opaque
data:
  run.sh: {{ include "datawave.datawaveInitContainer" . | b64enc }}